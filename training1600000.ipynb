{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import svm\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import string\n",
    "\n",
    "train_file = \"data/1600000/training.csv\"\n",
    "test_file = \"data/1600000/test.csv\"\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word_list = set(w.lower() for w in words.words())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punc = string.punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u'where', u'few', u'because', u'doing', u'some', u'hasn', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u're', u'does', u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u'were', u'here', u'shouldn', u'hers', u'by', u'on', u'about', u'couldn', u'of', u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u'mightn', u'wasn', u'your', u'from', u'her', u'their', u'aren', u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u'but', u'don', u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u'these', u'up', u'will', u'below', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u'so', u'y', u'the', u'having', u'once'])\n"
     ]
    }
   ],
   "source": [
    "print stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horrible'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"horrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\"\n",
      "#\n",
      "$\n",
      "%\n",
      "&\n",
      "'\n",
      "(\n",
      ")\n",
      "*\n",
      "+\n",
      ",\n",
      "-\n",
      ".\n",
      "/\n",
      ":\n",
      ";\n",
      "<\n",
      "=\n",
      ">\n",
      "?\n",
      "@\n",
      "[\n",
      "\\\n",
      "]\n",
      "^\n",
      "_\n",
      "`\n",
      "{\n",
      "|\n",
      "}\n",
      "~\n"
     ]
    }
   ],
   "source": [
    "# print stop_words\n",
    "with open(\"data/1600000/punct.csv\",'wb') as f:\n",
    "    for word in list(punc):\n",
    "        print word\n",
    "        f.write(word)\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s = \"0\",\"1467810369\",\"Mon Apr 06 22:19:45 PDT 2009\",\"NO_QUERY\",\"_TheSpecialOne_\",\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"\n",
    "s\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000 1600000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "label = []\n",
    "time = []\n",
    "text = []\n",
    "\n",
    "test_label = []\n",
    "test_text = []\n",
    "with open(train_file,'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for line in spamreader:\n",
    "        label.append(line[0])\n",
    "        text.append(line[5])\n",
    "    csvfile.close()\n",
    "\n",
    "print len(label),len(text)\n",
    "\n",
    "with open(test_file,'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for line in spamreader:\n",
    "        if line[0] != \"2\":\n",
    "            test_label.append(line[0])\n",
    "            test_text.append(line[5])\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_label)\n",
    "len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000\n",
      "1600000\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "\n",
    "all_text = []\n",
    "n = 0\n",
    "for line in text:\n",
    "    sentence = []\n",
    "    s = line.split()\n",
    "    for word in s:\n",
    "        if len(word)>2 and word not in stop_words:      \n",
    "            word = re.sub(\"[^A-Za-z]\",\"\",word)\n",
    "            if word:\n",
    "                try:\n",
    "                    word = lemmatizer.lemmatize(word.lower())\n",
    "                except:\n",
    "                    word = word.lower()\n",
    "                sentence.append(word)\n",
    "    all_text.append(' '.join(sentence))\n",
    "    n += 1\n",
    "\n",
    "print len(text)\n",
    "print len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "all_test_text = []\n",
    "n = 0\n",
    "for line in test_text:\n",
    "    sentence = []\n",
    "    s = line.split()\n",
    "    for word in s:\n",
    "        if len(word)>2 and word not in stop_words:      \n",
    "            word = re.sub(\"[^A-Za-z]\",\"\",word)\n",
    "            if word:\n",
    "                try:\n",
    "                    word = lemmatizer.lemmatize(word.lower())\n",
    "                except:\n",
    "                    word = word.lower()\n",
    "                sentence.append(word)\n",
    "    all_test_text.append(' '.join(sentence))\n",
    "    n += 1\n",
    "\n",
    "print len(all_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_input = open(\"data/1600000/training.pkl\",'wb')\n",
    "test_input = open(\"data/1600000/test.pkl\",'wb')\n",
    "pickle.dump(all_text,train_input)\n",
    "pickle.dump(all_text,train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1,binary = True)\n",
    "text_model = vectorizer.fit_transform(all_text)\n",
    "test_model = vectorizer.transform(all_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600000, 777666), (359, 777666))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model.shape,test_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9f1dec8016d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpredict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlg_p1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpredict2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlg_p2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlg1_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlg2_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlg1_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lg_p2 = linear_model.LogisticRegression(penalty='l2',C=1e5,solver = 'newton-cg')\n",
    "lg_p1 = linear_model.LogisticRegression(penalty='l1',C=1e5,solver = 'liblinear')\n",
    "lg_p2.fit(text_model,label)\n",
    "lg_p1.fit(text_model,label)\n",
    "predict1 = lg_p1.predict(test_model)\n",
    "predict2 = lg_p2.predict(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = open(\"data/1600000/lg1.pkl\",'wb')\n",
    "pickle.dump(lg_p1,path)\n",
    "path = open(\"data/1600000/lg2.pkl\",'wb')\n",
    "pickle.dump(lg_p2,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict1 = map(int,list(predict1))\n",
    "predict2 = map(int,list(predict2))\n",
    "test_label = map(int,list(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767441860465 0.725274725275 0.745762711864\n",
      "0.775862068966 0.741758241758 0.758426966292\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lg1_pre = precision_score(test_label,predict1)\n",
    "lg2_pre = precision_score(test_label,predict2)\n",
    "lg1_recall = recall_score(test_label,predict1)\n",
    "lg2_recall = recall_score(test_label,predict2)\n",
    "lg1_f1 = f1_score(test_label,predict1)\n",
    "lg2_f1 = f1_score(test_label,predict2)\n",
    "\n",
    "\n",
    "print lg1_pre,lg1_recall,lg1_f1\n",
    "print lg2_pre,lg2_recall,lg2_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "scores_nb = cross_val_score(dt,text_model,label,cv= 1,scoring='f1_macro')\n",
    "print np.mean(scores_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LinearSVC' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-59b4c8c8613c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnsvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnsvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnsvc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msvm_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LinearSVC' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "nsvc = LinearSVC(random_state=0)\n",
    "nsvc.fit(text_model,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814207650273 0.818681318681 0.816438356164\n"
     ]
    }
   ],
   "source": [
    "predict = nsvc.predict(test_model)\n",
    "predict = map(int,list(predict))\n",
    "for n in range(len(test_label)):\n",
    "    if test_label[n] == 4:\n",
    "        test_label[n] = 1\n",
    "    if predict[n] == 4:\n",
    "        predict[n] =1\n",
    "svm_pre = precision_score(test_label,predict)\n",
    "svm_recall = recall_score(test_label,predict)\n",
    "svm_f1 = f1_score(test_label,predict)\n",
    "print svm_pre,svm_recall,svm_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = open(\"data/1600000/svm.pkl\",'wb')\n",
    "pickle.dump(nsvc,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514450867052 0.978021978022 0.674242424242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "rf.fit(text_model,label)\n",
    "predict = rf.predict(test_model)\n",
    "predict = map(int,list(predict))\n",
    "for n in range(len(test_label)):\n",
    "    if test_label[n] == 4:\n",
    "        test_label[n] = 1\n",
    "    if predict[n] == 4:\n",
    "        predict[n] =1\n",
    "rf_pre = precision_score(test_label,predict)\n",
    "rf_recall = recall_score(test_label,predict)\n",
    "rf_f1 = f1_score(test_label,predict)\n",
    "print rf_pre,rf_recall,rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830508474576 0.807692307692 0.818941504178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(text_model,label)\n",
    "predict = nb.predict(test_model)\n",
    "predict = map(int,list(predict))\n",
    "for n in range(len(test_label)):\n",
    "    if test_label[n] == 4:\n",
    "        test_label[n] = 1\n",
    "    if predict[n] == 4:\n",
    "        predict[n] =1\n",
    "mnb_pre = precision_score(test_label,predict)\n",
    "mnb_recall = recall_score(test_label,predict)\n",
    "mnb_f1 = f1_score(test_label,predict)\n",
    "print mnb_pre,mnb_recall,mnb_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = open(\"data/1600000/randomforest.pkl\",'wb')\n",
    "pickle.dump(rf,path)\n",
    "path = open(\"data/1600000/multinomialNB.pkl\",'wb')\n",
    "pickle.dump(nb,path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
